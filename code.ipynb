{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import sniff, IP, TCP\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Constants\n",
    "WAITING_TIME = 30\n",
    "MAX_BYTES_THRESHOLD = 5000\n",
    "MAX_DURATION_THRESHOLD = 300\n",
    "MIN_PACKET_COUNT_THRESHOLD = 5\n",
    "T_dep = 60  # Time threshold in seconds\n",
    "N_dep = 5   # Difference in occurrences threshold\n",
    "Sdep_th = 0.5  # Dependency score threshold\n",
    "\n",
    "\n",
    "def save_data(data, file_path):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def read_data(file_path):\n",
    "    \"\"\"Read data from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "# Main flow\n",
    "\n",
    "def create_flow_key_from_packet(packet):\n",
    "    \"\"\"Generate a unique flow key based on packet IP and TCP headers.\"\"\"\n",
    "    return f\"{packet[IP].src}:{packet[TCP].sport}-{packet[IP].dst}:{packet[TCP].dport}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_or_create_stream(streams, flow_key, packet, current_time):\n",
    "    \"\"\"Update an existing stream or create a new one based on the WAITING_TIME.\"\"\"\n",
    "    if flow_key in streams:\n",
    "        last_session = streams[flow_key][-1]\n",
    "        last_packet_time = last_session['end_time']\n",
    "        if current_time - last_packet_time < WAITING_TIME:\n",
    "            last_session['packets'].append(packet.summary())\n",
    "            last_session['end_time'] = current_time\n",
    "            last_session['total_bytes'] += len(packet)\n",
    "        else:\n",
    "            new_session = {\n",
    "                'packets': [packet.summary()],\n",
    "                'start_time': current_time,\n",
    "                'end_time': current_time,\n",
    "                'total_bytes': len(packet)\n",
    "            }\n",
    "            streams[flow_key].append(new_session)\n",
    "    else:\n",
    "        streams[flow_key] = [{\n",
    "            'packets': [packet.summary()],\n",
    "            'start_time': current_time,\n",
    "            'end_time': current_time,\n",
    "            'total_bytes': len(packet)\n",
    "        }]\n",
    "    return streams\n",
    "\n",
    "def manage_stream(packet, streams):\n",
    "    \"\"\"Process each packet to manage stream data.\"\"\"\n",
    "    if IP in packet and TCP in packet:\n",
    "        flow_key = create_flow_key_from_packet(packet)\n",
    "        current_time = time.time()\n",
    "        streams = update_or_create_stream(streams, flow_key, packet, current_time)\n",
    "    return streams\n",
    "\n",
    "def read_pcap_file(pcap_file):\n",
    "    \"\"\"Read packets from a pcap file and manage streams.\"\"\"\n",
    "    streams = {}\n",
    "    def packet_processor(packet):\n",
    "        nonlocal streams\n",
    "        streams = manage_stream(packet, streams)\n",
    "    sniff(offline=pcap_file, prn=packet_processor, store=False)\n",
    "    return streams\n",
    "    \n",
    "streams = read_pcap_file('EX-3.pcap')\n",
    "save_data(streams, './1-streams_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_streams(streams):\n",
    "    \"\"\"Filter streams based on criteria such as bytes, duration, and packet count.\"\"\"\n",
    "    filtered_streams = {}\n",
    "    for flow_key, sessions in streams.items():\n",
    "        for session in sessions:\n",
    "            if (session['total_bytes'] < MAX_BYTES_THRESHOLD and\n",
    "                (session['end_time'] - session['start_time']) < MAX_DURATION_THRESHOLD and\n",
    "                len(session['packets']) > MIN_PACKET_COUNT_THRESHOLD):\n",
    "                if flow_key not in filtered_streams:\n",
    "                    filtered_streams[flow_key] = []\n",
    "                filtered_streams[flow_key].append(session)\n",
    "    return filtered_streams\n",
    "\n",
    "filtered_streams = filter_streams(streams)\n",
    "save_data(filtered_streams, './filtered_streams_data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_occurrences(streams):\n",
    "    \"\"\"Compute the number of occurrences for each flow.\"\"\"\n",
    "    occurrences = {}\n",
    "    for flow_key, sessions in streams.items():\n",
    "        occurrences[flow_key] = sum(len(session['packets']) for session in sessions)\n",
    "    return occurrences\n",
    "    \n",
    "occurrences = compute_occurrences(filtered_streams)\n",
    "save_data(occurrences, './occurrences_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dependencies(streams, occurrences, T_dep, N_dep, Sdep_th):\n",
    "    \"\"\"Extract two-level flow dependencies.\"\"\"\n",
    "    dependencies = {}\n",
    "    for flow_key in streams:\n",
    "        sorted_flows = sorted(streams[flow_key], key=lambda x: x['start_time'])\n",
    "        for i in range(len(sorted_flows)):\n",
    "            fi = sorted_flows[i]\n",
    "            print(fi)\n",
    "            if fi[flow_key] not in dependencies:\n",
    "                dependencies[fi[flow_key]] = {}\n",
    "            for j in range(i + 1, len(sorted_flows)):\n",
    "                fj = sorted_flows[j]\n",
    "                if abs(occurrences[fi[flow_key]] - occurrences[fj[flow_key]]) < N_dep:\n",
    "                    time_diff = fj['start_time'] - fi['end_time']\n",
    "                    if time_diff < T_dep:\n",
    "                        pair_key = f\"{fi[flow_key]}->{fj[flow_key]}\"\n",
    "                        if pair_key in dependencies[fi[flow_key]]:\n",
    "                            dependencies[fi[flow_key]][pair_key] += 1\n",
    "                        else:\n",
    "                            dependencies[fi[flow_key]][pair_key] = 1\n",
    "                        Tij = dependencies[fi[flow_key]][pair_key]\n",
    "                        Ni, Nj = occurrences[fi[flow_key]], occurrences[fj[flow_key]]\n",
    "                        Sdep = math.sqrt((Tij**2) / (Ni * Nj))\n",
    "                        if Sdep > Sdep_th:\n",
    "                            dependencies[fi[flow_key]][pair_key] = Sdep\n",
    "                        else:\n",
    "                            del dependencies[fi[flow_key]][pair_key]\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
